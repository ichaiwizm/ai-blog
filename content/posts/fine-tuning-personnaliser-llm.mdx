---
title: "Fine-tuning : Personnaliser un LLM"
description: "Apprenez a adapter un modele de langage a vos besoins specifiques avec le fine-tuning"
date: "2024-11-19"
tags: ["ia", "fine-tuning", "tutorial"]
image: "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&q=80"
published: true
category: "tutoriels"
series: "llm-pratique"
seriesOrder: 3
---

# Fine-tuning : Personnaliser un LLM

Le **fine-tuning** permet d'adapter un modele pre-entraine a vos cas d'usage specifiques. Decouvrez quand et comment l'utiliser.

## Qu'est-ce que le fine-tuning ?

C'est le processus d'entrainement supplementaire d'un modele existant sur vos propres donnees pour qu'il :
- Adopte un **style** specifique
- Apprenne un **vocabulaire** metier
- Suive des **instructions** particulieres

## Quand utiliser le fine-tuning ?

### Utilisez le fine-tuning si :
- Vous avez besoin d'un style de reponse tres specifique
- Le prompt engineering ne suffit plus
- Vous avez des centaines d'exemples de qualite

### N'utilisez PAS le fine-tuning si :
- Le RAG peut resoudre votre probleme
- Vous n'avez pas assez de donnees (moins de 100 exemples)
- Vos besoins changent frequemment

## Format des donnees

OpenAI utilise le format JSONL :

```json
{"messages": [{"role": "system", "content": "Tu es un assistant juridique."}, {"role": "user", "content": "C'est quoi un CDI ?"}, {"role": "assistant", "content": "Un CDI (Contrat a Duree Indeterminee) est..."}]}
{"messages": [{"role": "user", "content": "Explique le preavis"}, {"role": "assistant", "content": "Le preavis est la periode..."}]}
```

## Process avec OpenAI

### 1. Preparer les donnees

```python
import json

training_data = [
    {
        "messages": [
            {"role": "system", "content": "Tu es un expert en cuisine."},
            {"role": "user", "content": "Comment faire une bechamel ?"},
            {"role": "assistant", "content": "Voici ma recette de bechamel..."}
        ]
    },
    # ... plus d'exemples
]

with open("training.jsonl", "w") as f:
    for item in training_data:
        f.write(json.dumps(item) + "\n")
```

### 2. Uploader et lancer le fine-tuning

```python
from openai import OpenAI
client = OpenAI()

# Upload du fichier
file = client.files.create(
    file=open("training.jsonl", "rb"),
    purpose="fine-tune"
)

# Lancer le fine-tuning
job = client.fine_tuning.jobs.create(
    training_file=file.id,
    model="gpt-3.5-turbo"
)

print(f"Job ID: {job.id}")
```

### 3. Utiliser le modele fine-tune

```python
response = client.chat.completions.create(
    model="ft:gpt-3.5-turbo:your-org::your-model-id",
    messages=[{"role": "user", "content": "Comment faire une bechamel ?"}]
)
```

## Alternatives open-source

### LoRA (Low-Rank Adaptation)

Technique efficace qui modifie seulement une partie du modele :

```python
from peft import LoraConfig, get_peft_model

config = LoraConfig(
    r=8,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05
)

model = get_peft_model(base_model, config)
```

## Couts

| Modele | Entrainement | Inference |
|--------|--------------|-----------|
| GPT-3.5 Turbo | $0.008/1K tokens | $0.003/1K |
| GPT-4 | $0.03/1K tokens | $0.06/1K |

## Bonnes pratiques

1. **Qualite avant Quantite** - 100 bons exemples valent mieux que 1000 mauvais
2. **Diversite** - Couvrez tous les cas d'usage
3. **Validation** - Gardez un set de test
4. **Iteration** - Ameliorez progressivement

## Conclusion

Le fine-tuning est puissant mais pas toujours necessaire. Evaluez d'abord si le prompt engineering ou le RAG peuvent resoudre votre probleme.
